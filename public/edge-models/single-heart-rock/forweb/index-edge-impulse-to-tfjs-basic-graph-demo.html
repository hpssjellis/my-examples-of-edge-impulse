<!DOCTYPE html>
<html lang="en">
<head>    
  
</head>

<body>
<h5>  Version 0.8.14    </h5>

<!-- When working make the display:none; below to hide it  -->
<video id="myVideo" playsinline="" style="-webkit-transform: scaleX(-1); transform: scaleX(-1); width: auto; height: auto; display:inline; " ></video>  
<canvas id="myVideoCanvas" style=" display:none; "></canvas>    
<canvas id="my224x224Canvas" style="border: 1px solid #ddd; -webkit-transform: scaleX(-1); transform: scaleX(-1); " width="224" height="224"></canvas>
     
<div style="font-size:30px">Load Vision basic Graph Model TensorflowJS WebCam Demo</div>
Other Rocksetta Vanilla Javascript single page Tensorflowjs demos<br> 
<a href="https://www.rocksetta.com/tensorflowjs/default.php#tfjs-models">www.rocksetta.com/tensorflowjs/default.php#tfjs-models</a><br>
This workspace <a href="https://hpssjellis.github.io/my-examples-of-edge-impulse/public/edge-models/single-heart-rock/index.html">here</a><br> <br>  

<div id="myDiv01">...</div>       
    
<!-- check latest version numbers at
https://www.npmjs.com/package/@tensorflow/tfjs  
https://www.npmjs.com/package/@tensorflow/tfjs-backend-wasm
-->    

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.8.0"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-wasm@3.8.0/dist/tf-backend-wasm.js"></script>
    
<!-- Following could be in it's own index.js file. Easier to have it here so the web elements are pre-added  -->
<script>
        
// If using a transpiler this code is useful
//import * as tf from '@tensorflow/tfjs-core';
//import * as tfjsWasm from '@tensorflow/tfjs-backend-wasm';

// does not seem to help   
//tfjsWasm.setWasmPath('https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-wasm@latest/dist/tfjs-backend-wasm.wasm');
  
     
   //Global variables
   const EDGE_LABELS = {
      0: 'Unknown',
      1: 'Heart Rock',
      2: '2 not set',
      3: '3 not set',
      4: '4 not set',
      5: '5 not set',
      6: '6 not set'   

    }       
                   
// Camera setup        
const setupCamera = async function(){  
  myVideoSrc = document.getElementById('myVideo');
  const stream = await navigator.mediaDevices.getUserMedia({
    'audio': false,
    'video': { facingMode: 'user' },  // 'user' front camera, other option is 'environment' for rear camera
  });
  myVideoSrc.srcObject = stream;
   
  // put in await style later
  return new Promise((resolve) => {
    myVideoSrc.onloadedmetadata = () => {
      resolve(myVideoSrc);
    };
  });
}

// Main render function        
const renderPrediction = async function(){   
    

   myCTX.drawImage(myVideoSrc, 0, 0, myCanvasElement.width, myCanvasElement.height);
  
  
 tf.engine().startScope()
   const myImageTensor = await tf.browser.fromPixels(document.getElementById('my224x224Canvas')).toFloat().reshape([-1, 224, 224, 3]).div(tf.scalar(255)) ; 

 //  const myPredictions = await model.predict( myImageTensor );  
   const myPredictions = await model.predict( myImageTensor ).data();  
  
   console.log('myPredictions')  
   console.log(myPredictions)   
  
   document.getElementById('myDiv01').innerHTML = ''   // clear the div                                                                                              
   // document.getElementById('myDivTest').innerHTML += myPredictions                                                                                      
   document.getElementById('myDiv01').innerHTML += await myPredictions

 tf.engine().endScope()

 console.log('  Tensors after:', tf.memory().numTensors);   //,string  if unreliable is true

  // Just shows a possible layered canvas
  if (myPredictions.length > 0) {
    ctx.clearRect(0, 0, 224, 224);
     
    ctx.fillStyle = 'rgba(255, 0, 0, 0.5)';
    ctx.fillStyle = 'red';
    ctx.fillText('cool', 30, 30)
    ctx.fillRect(30, 10, 200, 100);
  }

  requestAnimationFrame(renderPrediction);
  
};
  
  
// Main setup function
const setupPage = async function(){     
  const state = { backend: 'wasm' }; 
        
  await tf.setBackend(state.backend);

  await setupCamera();
    
  myVideoSrc.play();

  videoWidth = myVideoSrc.videoWidth;
  videoHeight = myVideoSrc.videoHeight;
  myVideo.width = videoWidth;
  myVideo.height = videoHeight;

  canvas = document.getElementById('myVideoCanvas');
  canvas.width = videoWidth;
  canvas.height = videoHeight;
  
  // Make the smaller canvas context
  var myCanvasElement = document.getElementById('my224x224Canvas');
  var myCTX = myCanvasElement.getContext('2d');
  
  // Make an extra context to add overlays if wanted
  ctx = myCanvasElement.getContext('2d');          
  ctx.fillStyle = 'rgba(255, 0, 0, 0.5)';  
  
  // Load your https saved TFJS Graph model
  // must know input resolution in this case 224, 224
  model = await tf.loadGraphModel('https://hpssjellis.github.io/my-examples-of-edge-impulse/public/edge-models/single-heart-rock/forweb/model.json');     // should make the model a global variable
  const myZeros = tf.zeros([1, 224, 224, 3]);   // test with fake zeros data on for Graph vision model
  console.log('Testing model with zeros');
  model.predict(myZeros).print();                  // print to console
  console.log('Zeros test done above')
  
  await renderPrediction();
};

  
// Run the main program  
setupPage();

</script>
    
          
</body>
